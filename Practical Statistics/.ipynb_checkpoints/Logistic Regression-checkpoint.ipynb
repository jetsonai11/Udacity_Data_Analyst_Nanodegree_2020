{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "## Fitting Logistic Regression\n",
    "\n",
    "In this first notebook, you will be fitting a logistic regression model to a dataset where we would like to predict if a transaction is fraud or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>day</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28891</td>\n",
       "      <td>21.302600</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61629</td>\n",
       "      <td>22.932765</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53707</td>\n",
       "      <td>32.694992</td>\n",
       "      <td>weekday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47812</td>\n",
       "      <td>32.784252</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43455</td>\n",
       "      <td>17.756828</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id   duration      day  fraud\n",
       "0           28891  21.302600  weekend  False\n",
       "1           61629  22.932765  weekend  False\n",
       "2           53707  32.694992  weekday  False\n",
       "3           47812  32.784252  weekend  False\n",
       "4           43455  17.756828  weekend  False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data/fraud_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['weekday', 'weekend']] = pd.get_dummies(df['day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['no_fraud', 'fraud']] = pd.get_dummies(df['fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>day</th>\n",
       "      <th>fraud</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>no_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28891</td>\n",
       "      <td>21.302600</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61629</td>\n",
       "      <td>22.932765</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53707</td>\n",
       "      <td>32.694992</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47812</td>\n",
       "      <td>32.784252</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43455</td>\n",
       "      <td>17.756828</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td>19176</td>\n",
       "      <td>24.887279</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>87903</td>\n",
       "      <td>30.312163</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>29785</td>\n",
       "      <td>29.622158</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>63507</td>\n",
       "      <td>35.631321</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>74587</td>\n",
       "      <td>36.356404</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8793 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id   duration      day  fraud  weekday  weekend  no_fraud\n",
       "0              28891  21.302600  weekend      0        0        1         1\n",
       "1              61629  22.932765  weekend      0        0        1         1\n",
       "2              53707  32.694992  weekday      0        1        0         1\n",
       "3              47812  32.784252  weekend      0        0        1         1\n",
       "4              43455  17.756828  weekend      0        0        1         1\n",
       "...              ...        ...      ...    ...      ...      ...       ...\n",
       "8788           19176  24.887279  weekday      0        1        0         1\n",
       "8789           87903  30.312163  weekday      0        1        0         1\n",
       "8790           29785  29.622158  weekday      0        1        0         1\n",
       "8791           63507  35.631321  weekday      0        1        0         1\n",
       "8792           74587  36.356404  weekend      0        0        1         1\n",
       "\n",
       "[8793 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['False', 'weekend'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingjue/opt/anaconda3/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py:1747: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/Users/mingjue/opt/anaconda3/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py:1800: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "/Users/mingjue/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/Users/mingjue/opt/anaconda3/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>fraud</td>      <th>  No. Observations:  </th>  <td>  8793</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  8790</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 13 Jun 2020</td> <th>  Pseudo R-squ.:     </th>  <td>   inf</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:38:40</td>     <th>  Log-Likelihood:    </th> <td>    -inf</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>  0.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>    9.8709</td> <td>    1.944</td> <td>    5.078</td> <td> 0.000</td> <td>    6.061</td> <td>   13.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weekday</th>   <td>    2.5465</td> <td>    0.904</td> <td>    2.816</td> <td> 0.005</td> <td>    0.774</td> <td>    4.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>duration</th>  <td>   -1.4637</td> <td>    0.290</td> <td>   -5.039</td> <td> 0.000</td> <td>   -2.033</td> <td>   -0.894</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.98 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  fraud   No. Observations:                 8793\n",
       "Model:                          Logit   Df Residuals:                     8790\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sat, 13 Jun 2020   Pseudo R-squ.:                     inf\n",
       "Time:                        21:38:40   Log-Likelihood:                   -inf\n",
       "converged:                       True   LL-Null:                        0.0000\n",
       "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept      9.8709      1.944      5.078      0.000       6.061      13.681\n",
       "weekday        2.5465      0.904      2.816      0.005       0.774       4.319\n",
       "duration      -1.4637      0.290     -5.039      0.000      -2.033      -0.894\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.98 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intercept'] = 1\n",
    "\n",
    "logit_mod = sm.Logit(df['fraud'], df[['intercept', 'weekday', 'duration']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.762357271496972, 4.321921089278333)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(2.5465), 1/np.exp(-1.4637)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting Results of Logistic Regression\n",
    "\n",
    "In this notebook (and quizzes), you will be getting some practice with interpreting the coefficients in logistic regression.  Using what you saw in the previous video should be helpful in assisting with this notebook.\n",
    "\n",
    "The dataset contains four variables: `admit`, `gre`, `gpa`, and `prestige`:\n",
    "\n",
    "* `admit` is a binary variable. It indicates whether or not a candidate was admitted into UCLA (admit = 1) our not (admit = 0).\n",
    "* `gre` is the GRE score. GRE stands for Graduate Record Examination.\n",
    "* `gpa` stands for Grade Point Average.\n",
    "* `prestige` is the prestige of an applicant alta mater (the school attended before applying), with 1 being the highest (highest prestige) and 4 as the lowest (not prestigious).\n",
    "\n",
    "To start, let's read in the necessary libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige\n",
       "0      0  380  3.61         3\n",
       "1      1  660  3.67         3\n",
       "2      1  800  4.00         1\n",
       "3      1  640  3.19         4\n",
       "4      0  520  2.93         4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/admissions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['prest_1', 'prest_2', 'prest_3','prest_4',]] = pd.get_dummies(df['prestige'])\n",
    "df.drop('prestige', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 13 Jun 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>21:38:41</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -3.8769</td> <td>    1.142</td> <td>   -3.393</td> <td> 0.001</td> <td>   -6.116</td> <td>   -1.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>       <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>       <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128</td> <td>    1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prest_2</th>   <td>   -0.6801</td> <td>    0.317</td> <td>   -2.146</td> <td> 0.032</td> <td>   -1.301</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prest_3</th>   <td>   -1.3387</td> <td>    0.345</td> <td>   -3.882</td> <td> 0.000</td> <td>   -2.015</td> <td>   -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prest_4</th>   <td>   -1.5534</td> <td>    0.417</td> <td>   -3.721</td> <td> 0.000</td> <td>   -2.372</td> <td>   -0.735</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Sat, 13 Jun 2020   Pseudo R-squ.:                 0.08166\n",
       "Time:                        21:38:41   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.176e-07\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -3.8769      1.142     -3.393      0.001      -6.116      -1.638\n",
       "gre            0.0022      0.001      2.028      0.043    7.44e-05       0.004\n",
       "gpa            0.7793      0.333      2.344      0.019       0.128       1.431\n",
       "prest_2       -0.6801      0.317     -2.146      0.032      -1.301      -0.059\n",
       "prest_3       -1.3387      0.345     -3.882      0.000      -2.015      -0.663\n",
       "prest_4       -1.5534      0.417     -3.721      0.000      -2.372      -0.735\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intercept'] = 1\n",
    "\n",
    "logit_mod = sm.Logit(df['admit'], df[['intercept', 'gre', 'gpa', 'prest_2', 'prest_3', 'prest_4']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0022024217756431,\n",
       " 2.1799457692483717,\n",
       " 1.9740751298733885,\n",
       " 3.81408197450317,\n",
       " 4.727516444398727)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.0022), np.exp(0.7793), 1/np.exp(-0.6801), 1/np.exp(-1.3387), 1/np.exp(-1.5534)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics + Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prest_1</th>\n",
       "      <th>prest_2</th>\n",
       "      <th>prest_3</th>\n",
       "      <th>prest_4</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prest_1  prest_2  prest_3  prest_4  intercept\n",
       "0      0  380  3.61        0        0        1        0          1\n",
       "1      1  660  3.67        0        0        1        0          1\n",
       "2      1  800  4.00        1        0        0        0          1\n",
       "3      1  640  3.19        0        0        0        1          1\n",
       "4      0  520  2.93        0        0        0        1          1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Change prestige to dummy variable columns that are added to `df`.  Then divide your data into training and test data.  Create your test set as 20% of the data, and use a random state of 0.  Your response should be the `admit` column.  [Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) are the docs, which can also find with a quick google search if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gre', 'gpa', 'prest_1', 'prest_2', 'prest_3']]\n",
    "y = df['admit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now use [sklearn's Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to fit a logistic model using `gre`, `gpa`, and 3 of your `prestige` dummy variables.  For now, fit the logistic regression model without changing any of the hyperparameters.  \n",
    "\n",
    "The usual steps are:\n",
    "* Instantiate\n",
    "* Fit (on train)\n",
    "* Predict (on test)\n",
    "* Score (compare predict to test)\n",
    "\n",
    "As a first score, obtain the [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).  Then answer the first question below about how well your model performed on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingjue/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56,  0],\n",
       "       [19,  5]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_preds = lr_model.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now, try out a few additional metrics: [precision](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [recall](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), and [accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) are all popular metrics, which you saw with Sebastian.  You could compute these directly from the confusion matrix, but you can also use these built in functions in sklearn.\n",
    "\n",
    "Another very popular set of metrics are [ROC curves and AUC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py).  These actually use the probability from the logistic regression models, and not just the label.  [This](http://blog.yhat.com/posts/roc-curves.html) is also a great resource for understanding ROC curves and AUC.\n",
    "\n",
    "Try out these metrics to answer the second quiz question below.  I also provided the ROC plot below.  The ideal case is for this to shoot all the way to the upper left hand corner.  Again, these are discussed in more detail in the Machine Learning Udacity program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7625\n",
      "0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_preds))\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "print(recall_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = lr_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
